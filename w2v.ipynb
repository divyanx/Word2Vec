{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "corpus = []\n",
    "# read json file\n",
    "fileName = 'Electronics_5.json'\n",
    "# read\n",
    "with open(fileName, \"r\") as read_file:\n",
    "    i = 0\n",
    "    l = read_file.readline()\n",
    "    while l and i < 10:\n",
    "        i+=1\n",
    "        l_dict = json.loads(l)\n",
    "        review = l_dict[\"reviewText\"]\n",
    "        r_list = review.split('.')\n",
    "        for r in r_list:\n",
    "            r = re.sub('[^a-zA-Z]', ' ', r)\n",
    "            r = r.lower()\n",
    "            r = r.split()\n",
    "            r = [w for w in r if not w in set(string.punctuation)]\n",
    "            r = ' '.join(r)\n",
    "            if r != '':\n",
    "                corpus.append(r)\n",
    "        l = read_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we got this gps for my husband who is an otr over the road trucker', 'very impressed with the shipping time it arrived a few days earlier than expected', 'within a week of use however it started freezing up', 'could of just been a glitch in that unit', 'worked great when it worked will work great for the normal person as well but does have the trucker option', 'the big truck routes tells you when a scale is coming up ect', 'love the bigger screen the ease of use the ease of putting addresses into memory', 'nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that s just my luck', 'i contacted the seller and within minutes of my email i received a email back with instructions for an exchange very impressed all the way around', 'i m a professional otr truck driver and i bought a tnd at a truck stop hoping to make my life easier']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def remove_stop_words(corpus):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        #print(word)\n",
    "        words.append(word)\n",
    "\n",
    "print(len(words))\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we have word set by which we will have word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'quality', 'way', 'tv', 'parked', 'cincinnati', 'second', 'makes', 'company', 'see', 'e', 'mouth', 'alot', 'refused', 'follow', 'country', 'computer', 'recoverable', 'impression', 'longer', 'ton', 'make', 'supposed', 'weight', 'ran', 'home', 'total', 'normal', 'omission', 'boot', 'hop', 'information', 'following', 'deserves', 'self', 'getting', 'cards', 'connection', 'found', 'reroute', 'interstate', 'past', 'extend', 'garmin', 'bottom', 'un', 'tvs', 'mean', 'area', 'the', 'million', 'cannot', 'north', 'all', 'got', 'printer', 'totally', 'city', 'years', 'enter', 'shortest', 'friends', 'worked', 'sites', 'husband', 'tried', 'hoping', 'concept', 'much', 'cable', 'short', 'least', 'happy', 'tries', 'away', 'else', 'allot', 'route', 'bridges', 'chose', 'determine', 'truck', 'completely', 'best', 'months', 'means', 'whats', 'price', 'owned', 'pros', 'works', 'ability', 'online', 'bet', 'traveling', 'coordinate', 'miles', 'however', 'amongst', 'furthermore', 'judgement', 'challenging', 'complaints', 'tons', 'built', 'operate', 'time', 'roads', 'pretty', 'response', 'decided', 'update', 'setup', 'charging', 'non', 'sitting', 'gave', 'lost', 'hd', 'took', 'determines', 'set', 'product', 'less', 'plugin', 'as', 'volumecons', 'reason', 'appeared', 'limited', 'verified', 'example', 'word', 'perusing', 'box', 'that', 'instead', 'routed', 'it', 'software', 'cheap', 'illegal', 'companies', 'thinks', 'near', 'needs', 'pages', 'write', 'multiple', 'suggestion', 'macnally', 'keep', 'things', 'arrived', 'fb', 'routes', 'compared', 'really', 'easier', 'intelliroute', 'features', 'good', 'rand', 'long', 'upwards', 'smart', 'mistakes', 'my', 'awesome', 'tnd', 'map', 'like', 'putting', 'give', 'seems', 'something', 'otherwise', 'choices', 'samsung', 'does', 'rig', 'main', 'not', 'three', 'said', 'determining', 'mulling', 'phone', 'unit', 'ect', 'pickup', 'scale', 'selling', 'size', 'bad', 'happened', 'me', 'week', 'patch', 'drive', 'or', 'what', 'simple', 'figure', 'locations', 'updates', 'messing', 'stars', 'head', 'professional', 'six', 'smarttv', 'received', 'detected', 'common', 'expected', 'busy', 'laptop', 'never', 'poi', 'life', 'was', 'available', 'and', 'though', 'line', 'thats', 'listing', 'a', 'fairly', 'pleasing', 'phoenix', 'laden', 'stuff', 'impressed', 'passed', 'mil', 'basic', 'every', 'bit', 'corrected', 'instructions', 'imagesoutstanding', 'others', 'reasons', 'complexity', 'solid', 'plug', 'shipping', 'mind', 'done', 'place', 'thorough', 'note', 'entering', 'driven', 'especially', 'one', 'hazmat', 'points', 'highway', 'go', 'plugs', 'mine', 'freezing', 'period', 'telling', 'started', 'addresses', 'warning', 'crashed', 'pricey', 'real', 'needed', 'unimpressed', 'nice', 'stop', 'programmed', 'friendly', 'flummoxed', 'find', 'designed', 'wobbly', 'your', 'stops', 'sometimes', 'let', 'backside', 'drivers', 'would', 'great', 'address', 'viasa', 'send', 'trucks', 'its', 'restrictions', 'sold', 'vias', 'chain', 'plain', 'updated', 'year', 'attempt', 'info', 'force', 'factors', 'finally', 'manual', 'to', 'excited', 'first', 'loosely', 'major', 'routings', 'an', 'chance', 'specific', 'excellent', 'items', 'within', 'preferred', 'four', 'extra', 'email', 'hauling', 'listening', 'right', 'wealth', 'potential', 'think', 'love', 'playing', 'various', 'directions', 'trucker', 'important', 'according', 'fine', 'actually', 'for', 'light', 'prior', 'made', 'accessible', 'forums', 'purchased', 'even', 'via', 'surface', 'review', 'volume', 'viewing', 'units', 'print', 'described', 'magnificent', 'earlier', 'atlas', 'prossesor', 'buy', 'yet', 'room', 'road', 'grafics', 'memory', 'outdated', 'appears', 'sprint', 'installed', 'might', 'move', 'cables', 'google', 'stand', 'state', 'cell', 'take', 'current', 'money', 'ones', 'close', 'fact', 'purchase', 'returned', 'thru', 'spent', 'hotel', 'connect', 'databases', 'cost', 'explain', 'highways', 'based', 'fastest', 'buying', 'change', 'big', 'noticed', 'worth', 'along', 'easily', 'probably', 'wayne', 'dollar', 'curve', 'cool', 'thought', 'trouble', 'intersection', 'picture', 'coming', 'days', 'belong', 'rock', 'card', 'friend', 'going', 'leadway', 'os', 'lg', 'inability', 'nowhere', 'point', 'colorado', 'sure', 'version', 'devices', 'notifications', 'gotten', 'somewhat', 'field', 'us', 'hello', 'several', 'item', 'ways', 'left', 'turned', 'updating', 'considering', 'driver', 'boiled', 'exception', 'town', 'still', 'reviews', 'durably', 'series', 'situation', 'dock', 'high', 'car', 'tested', 'next', 'of', 'usefull', 'also', 'another', 'plan', 'know', 'believe', 'expert', 'watching', 'videos', 'informed', 'adapter', 'bought', 'willing', 'unusual', 'freeway', 'length', 'option', 'oh', 'source', 'weird', 'gps', 'easy', 'checks', 'little', 'previously', 'wanted', 'consideration', 'using', 'navteq', 'anything', 'across', 'pick', 'bigger', 'seller', 'sd', 'forcing', 'weekly', 'standard', 'port', 'evertime', 'work', 'side', 'whether', 'live', 'connects', 'south', 'minute', 'adaptor', 'otr', 'told', 'in', 'sent', 'get', 'height', 'cars', 'too', 'trips', 'deal', 'couple', 'course', 'nothing', 'five', 'ever', 'tell', 'quite', 'luck', 'dozen', 'is', 'unbelievable', 'fits', 'same', 'well', 'exciting', 'unless', 'tools', 'different', 'blocks', 'put', 'since', 'disagree', 'waiting', 'listed', 'add', 'recommend', 'ease', 'aesthetically', 'indeed', 'old', 'feature', 'contacted', 'az', 'routing', 'with', 'workable', 'check', 'residential', 'representative', 'you', 'turn', 'able', 'favorite', 'people', 'must', 'exchange', 'went', 'without', 'mcnally', 'posted', 'due', 'setting', 'unacceptable', 'rated', 'glitch', 'this', 'unfair', 'photos', 'tells', 'xyz', 'mixed', 'have', 'west', 'cross', 'times', 'mentioned', 'user', 'almost', 'adequate', 'chosen', 'many', 'hdmi', 'connected', 'device', 'program', 'movies', 'around', 'sum', 'overwhelming', 'initial', 'screen', 'monitors', 'server', 'learning', 'holding', 'denver', 'track', 'disconnects', 'person', 'street', 'unique', 'half', 'sharing', 'want', 'need', 'screenterrific', 'strictly', 'accessory', 'wrong', 'seem', 'twice', 'feet', 'ft', 'other', 'sto', 'i', 'better', 'problem', 'lacking', 'garmen', 'fall', 'use', 'back', 'functionality', 'tracking', 'nook', 'trip', 'large', 'forth', 'blocked', 'install', 'used', 'could', 'streets', 'streaming', 'po', 'power', 'county', 'conjested', 'restriction', 'slow', 'bone', 'if', 'weather', 'ticket', 'minutes', 'advised', 'say', 'today', 'hdtv', 'thing', 'seconds', 'yards', 'mileage'}\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got gps husband otr road trucker\n",
      "impressed shipping time arrived days earlier expected\n",
      "within week use however started freezing\n",
      "could glitch unit\n",
      "worked great worked work great normal person well the trucker option\n",
      "big truck routes tells scale coming ect\n",
      "love bigger screen the ease use the ease of putting addresses memory\n",
      "nothing really bad say unit the exception freezing probably one million luck\n",
      "contacted seller within minutes email i received email back instructions exchange impressed the way around\n",
      "professional otr truck driver i bought a tnd a truck stop hoping make life easier\n",
      "rand mcnally listening first thing charging connect it laptop install software and attempt to update it\n",
      "software detected problem update wanted my home address could sent a patch sd card\n",
      "hello think i unusual home address po box that a friend checks weekly that i might get check every six months\n",
      "live truck truck stops\n",
      "need make patch available sd card you send sd cards to the truck stops the devices sold\n",
      "ran update program multiple times the program said the tnd completely updated\n",
      "programmed height the length the weight rig and told i preferred highways\n",
      "parked truck stop cincinnati oh area\n",
      "next pickup miles freeway the side couple of blocks\n",
      "cell phone gps sprint said get freeway to get to my pickup\n",
      "tnd routed thru miles residential streets finally getting me pickup\n",
      "exciting especially since every time refused turn street posted trucks tnd took almost minutes to figure a route happened multiple times short trip\n",
      "decided give another chance\n",
      "pickup north side cincinnati of i needed head to phoenix az via i\n",
      "easy route hop drive west and south to intersection i\n",
      "indeed cell phone advised\n",
      "tnd however wanted route surface streets across the city pick the side the city\n",
      "turned next time i passed truck stop the chain i purchased it i returned it and got money back\n",
      "spent cheap printer\n",
      "take minute set route google print\n",
      "gotten lost yet several cross country trips\n",
      "well say\n",
      "unit truck four days\n",
      "prior garmin non truck gps\n",
      "one favorite features unit ability plan route determining mileage using the stop via feature\n",
      "would using map i would route several different ways forcing unit putting stops vias different locations along the route otherwise like gps determines what it thinks is the best route\n",
      "could add via stop points route based mileage and factors determine best route to take\n",
      "multiple stops ability route the important reason the garmin\n",
      "however truck specific\n",
      "considering hauling strictly hazmat i wanted something would take that consideration\n",
      "perusing various forums review sites word mouth choices boiled garmin the rand mcnally intelliroute tnd\n",
      "even though quite bit garmin chose the tnd several reasons\n",
      "main one the extra screen size ability coordinate the rand mcnally truck atlas and also its ease updating\n",
      "first impression tnd\n",
      "seems aesthetically pleasing durably built unit\n",
      "first thing noticed slow boot compared to old garmin\n",
      "whether unique tnd is common amongst truck specific gps units cannot tell really big deal\n",
      "second thing noticed the overwhelming wealth information put forth\n",
      "might explain manual available via the tnd dock well pages long\n",
      "somewhat learning curve unit\n",
      "next thing noticed the complexity entering routes\n",
      "previously mentioned like force preferred routing use stops vias\n",
      "big go unit\n",
      "enter multiple stops vias nowhere near user friendly as old garmin\n",
      "furthermore way determine total mileage route you chosen could the garmin\n",
      "totally flummoxed appeared omission one of best routing tools trucker could went online verified an expert source connected rand mcnally that feature a couple updates the line and was available point\n",
      "unbelievable\n",
      "also forcing unit follow specific route challenging\n",
      "unit price feature laden find this totally unacceptable\n",
      "still mulling selling unit buying garmin\n",
      "really like gps screen magnificent the volume is awesome\n",
      "another thing noticed i think unique unit is weird routing\n",
      "never owned truck specific gps playing one a couple days i get impression rand macnally the others that use navteq done take a plain old car specific navteq map and a road atlas with truck restrictions and made notifications the map\n",
      "databases thorough listing every road in country\n",
      "mean unit route roads you belong\n",
      "today coming home tried routing several ton county roads\n",
      "means that truck is limited unless road is posted tons\n",
      "county roads restriction listed rand mcnally road atlas believe that is not listed\n",
      "also unacceptable unit price sold truck specific\n",
      "however willing bet truck specific units the way one ever done truck specific version navteq\n",
      "another bone pick poi\n",
      "truck specific ones the others seem somewhat outdated\n",
      "think garmin least the ones i used current\n",
      "would also nice could add poi sto sum it i keep unit little longer see if i make it workable\n",
      "go back garmin\n",
      "like concept i like the unit point i say i somewhat unimpressed\n",
      "pros large screenterrific imagesoutstanding volumecons inability determine route mileage multiple stops viasa somewhat outdated poi information\n",
      "non truck specific routings\n",
      "cost\n",
      "going write long review even thought unit deserves one\n",
      "driven well mil miles done routing i pretty know whats fastest and shortest\n",
      "using basic garmin past three years gps unit get trouble you let\n",
      "really excited unit due size the features\n",
      "allot great grafics screen info thats usefull\n",
      "basic item lacking was the gps tracking\n",
      "gave unit allot leadway mistakes due fact allot of cool stuff that it its ability to track route you even close to the basic garmin could due\n",
      "like prossesor installed the tnd years old\n",
      "example needed make simple route change i\n",
      "e\n",
      "town next street due to the fact make the turn the street blocked would take the tnd upwards seconds to minute a half to reroute\n",
      "sitting stop light waiting directions waiting long cars backside make happy\n",
      "problem happened evertime reroute weather a simple street change a major highway change\n",
      "also time turned the unit would take twice long boot\n",
      "least dozen times a week put wrong roads made a wrong turn it got it self lost\n",
      "\n",
      "e\n",
      "take left xyz street ones drive way\n",
      "turn left yards turn less feet away\n",
      "might think conjested city situation might get a little mixed in country\n",
      "twice put bridges\n",
      "course made sure truck setting supposed\n",
      "also updated os version via rand mcnally\n",
      "all expected alot unit got unit of field tested people that drive allot\n",
      "many route mistakes\n",
      "going back basic garmin\n",
      "complaints three friends bought unit have the same complaints\n",
      "us returned units\n",
      "mine year got\n",
      "tries route non truck routes telling truck route illegal me\n",
      "bad problem even interstate denver colorado is listed according this gps a non truck route route city instead\n",
      "several drivers within company one half crashed un recoverable state\n",
      "company representative said rand mcnally informed that gps designed say long period time\n",
      "really truck driver gps\n",
      "one driver dollar ticket due gps routing wrong road\n",
      "companies response update the unit\n",
      "mine year i never noticed one update corrected functionality seem keep messing tools\n",
      "want gps routes i wanted tools i buy software computer\n",
      "suggestion nice garmen\n",
      "one rated cars actually routes better one rated for trucks\n",
      "wayne\n",
      "using nook hd\n",
      "works described\n",
      "hd picture samsung tv excellent\n",
      "cable wobbly sometimes disconnects\n",
      "price completely unfair works the nook hd and hd\n",
      "adaptor real easy setup use right box\n",
      "problem it well worth purchase\n",
      "recommend adaptor much viewing nook videos your hdtv\n",
      "disagree reviews length the adaptor i found fairly adequate to it connected to tv\n",
      "right long too short was able place nook right connection the tv stand it not fall or anything else it fine\n",
      "use judgement busy watching movies\n",
      "adapter easily connects nook hd my hdtv hdmi cable\n",
      "good traveling makes hotel tv potential smart tv long is accessible hdmi port\n",
      "also good sharing photos fb bigger screen\n",
      "bit pricey a good accessory\n",
      "sure note nook hd hd series\n",
      "work standard nook\n",
      "product really works great found following items need keep mind you must power adapter connected to work\n",
      "plugs the bottom\n",
      "appears it needs power nook power adapter operate\n",
      "plug fits loosely cannot move the nook around much without holding the adapter in place\n",
      "initial plugin seems need rock it around to get connection it seems solid\n",
      "works ft high quality hdmi cable put nook across the room with you\n",
      "tested cheap cables\n",
      "warning\n",
      "found lg smarttv years back work adapter does not seem work with many things\n",
      "bad software\n",
      "adapter works fine hdmi devices used like monitors i sure other tvs\n",
      "gave five stars it really nice extend screen use nook streaming server to your tv\n",
      "nice made device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>got</td>\n",
       "      <td>gps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>got</td>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gps</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gps</td>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gps</td>\n",
       "      <td>otr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>husband</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>husband</td>\n",
       "      <td>gps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>husband</td>\n",
       "      <td>otr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>husband</td>\n",
       "      <td>road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>otr</td>\n",
       "      <td>gps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input    label\n",
       "0      got      gps\n",
       "1      got  husband\n",
       "2      gps      got\n",
       "3      gps  husband\n",
       "4      gps      otr\n",
       "5  husband      got\n",
       "6  husband      gps\n",
       "7  husband      otr\n",
       "8  husband     road\n",
       "9      otr      gps"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/divyansh/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] \n",
    "Y = [] \n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  nan\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.939799   -0.07269198 -0.97047895 ...  0.7051742  -0.15360045\n",
      "   0.51146656]\n",
      " [-0.1873407  -1.1416229   0.5282674  ...  0.16597298  0.7074446\n",
      "  -0.72289747]\n",
      " [ 1.52764     0.25991395 -0.7446072  ...  1.1543721   1.399253\n",
      "  -0.36812222]\n",
      " ...\n",
      " [-0.43489447 -0.7359016  -0.1985785  ...  0.23103496 -0.19230562\n",
      "   0.49056885]\n",
      " [ 1.794864    2.3677323  -0.14232966 ... -0.20893413  0.12733576\n",
      "   1.1365646 ]\n",
      " [-1.3320976  -1.1418248  -1.0579894  ...  0.19501397 -0.72448903\n",
      "   0.29870006]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>days</td>\n",
       "      <td>0.939799</td>\n",
       "      <td>-0.072692</td>\n",
       "      <td>-0.970479</td>\n",
       "      <td>0.764277</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.117511</td>\n",
       "      <td>-0.822014</td>\n",
       "      <td>0.656016</td>\n",
       "      <td>0.222889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246136</td>\n",
       "      <td>-0.994582</td>\n",
       "      <td>1.446947</td>\n",
       "      <td>-0.132918</td>\n",
       "      <td>1.080357</td>\n",
       "      <td>1.574163</td>\n",
       "      <td>1.063431</td>\n",
       "      <td>0.705174</td>\n",
       "      <td>-0.153600</td>\n",
       "      <td>0.511467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glitch</td>\n",
       "      <td>-0.187341</td>\n",
       "      <td>-1.141623</td>\n",
       "      <td>0.528267</td>\n",
       "      <td>0.468640</td>\n",
       "      <td>-1.393529</td>\n",
       "      <td>0.200473</td>\n",
       "      <td>0.410444</td>\n",
       "      <td>0.088482</td>\n",
       "      <td>-1.088427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402051</td>\n",
       "      <td>1.283518</td>\n",
       "      <td>-0.739742</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.633267</td>\n",
       "      <td>1.597046</td>\n",
       "      <td>1.230733</td>\n",
       "      <td>0.165973</td>\n",
       "      <td>0.707445</td>\n",
       "      <td>-0.722897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unit</td>\n",
       "      <td>1.527640</td>\n",
       "      <td>0.259914</td>\n",
       "      <td>-0.744607</td>\n",
       "      <td>-1.541466</td>\n",
       "      <td>1.504610</td>\n",
       "      <td>0.358284</td>\n",
       "      <td>-0.055283</td>\n",
       "      <td>0.531721</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790788</td>\n",
       "      <td>-0.022923</td>\n",
       "      <td>0.614775</td>\n",
       "      <td>0.558936</td>\n",
       "      <td>0.518648</td>\n",
       "      <td>-0.755605</td>\n",
       "      <td>0.235046</td>\n",
       "      <td>1.154372</td>\n",
       "      <td>1.399253</td>\n",
       "      <td>-0.368122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>1.088039</td>\n",
       "      <td>0.799649</td>\n",
       "      <td>-0.056783</td>\n",
       "      <td>-0.642312</td>\n",
       "      <td>0.689861</td>\n",
       "      <td>0.118699</td>\n",
       "      <td>-0.260751</td>\n",
       "      <td>1.538907</td>\n",
       "      <td>-0.531299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385175</td>\n",
       "      <td>1.642984</td>\n",
       "      <td>-0.324092</td>\n",
       "      <td>1.695246</td>\n",
       "      <td>0.725493</td>\n",
       "      <td>-0.499327</td>\n",
       "      <td>0.758729</td>\n",
       "      <td>0.740417</td>\n",
       "      <td>-0.460985</td>\n",
       "      <td>1.670823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exchange</td>\n",
       "      <td>0.041626</td>\n",
       "      <td>0.385806</td>\n",
       "      <td>-0.161574</td>\n",
       "      <td>1.478175</td>\n",
       "      <td>-0.883460</td>\n",
       "      <td>0.212744</td>\n",
       "      <td>-0.285856</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>1.351103</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041175</td>\n",
       "      <td>1.338348</td>\n",
       "      <td>0.501510</td>\n",
       "      <td>-1.734342</td>\n",
       "      <td>0.717494</td>\n",
       "      <td>-0.605008</td>\n",
       "      <td>0.322809</td>\n",
       "      <td>0.563093</td>\n",
       "      <td>-0.080149</td>\n",
       "      <td>-0.035231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>of</td>\n",
       "      <td>0.869975</td>\n",
       "      <td>-0.539592</td>\n",
       "      <td>1.452256</td>\n",
       "      <td>1.815241</td>\n",
       "      <td>0.302172</td>\n",
       "      <td>1.918517</td>\n",
       "      <td>-1.295815</td>\n",
       "      <td>-0.315433</td>\n",
       "      <td>0.311235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060091</td>\n",
       "      <td>-1.204293</td>\n",
       "      <td>-0.887394</td>\n",
       "      <td>0.324741</td>\n",
       "      <td>0.756478</td>\n",
       "      <td>-0.259807</td>\n",
       "      <td>-0.073089</td>\n",
       "      <td>-0.940413</td>\n",
       "      <td>0.499771</td>\n",
       "      <td>0.622067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>impressed</td>\n",
       "      <td>0.326595</td>\n",
       "      <td>-0.304986</td>\n",
       "      <td>2.031691</td>\n",
       "      <td>-0.350441</td>\n",
       "      <td>-1.221668</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.948178</td>\n",
       "      <td>0.335767</td>\n",
       "      <td>0.458206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501210</td>\n",
       "      <td>-0.162042</td>\n",
       "      <td>-0.170697</td>\n",
       "      <td>-1.744612</td>\n",
       "      <td>0.302444</td>\n",
       "      <td>1.170005</td>\n",
       "      <td>0.598283</td>\n",
       "      <td>-2.103957</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>-0.583350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>coming</td>\n",
       "      <td>-0.434894</td>\n",
       "      <td>-0.735902</td>\n",
       "      <td>-0.198579</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>1.309612</td>\n",
       "      <td>0.546925</td>\n",
       "      <td>1.014227</td>\n",
       "      <td>0.202772</td>\n",
       "      <td>0.718133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642574</td>\n",
       "      <td>-0.287559</td>\n",
       "      <td>-0.582734</td>\n",
       "      <td>-0.065121</td>\n",
       "      <td>0.664541</td>\n",
       "      <td>-1.016463</td>\n",
       "      <td>0.321847</td>\n",
       "      <td>0.231035</td>\n",
       "      <td>-0.192306</td>\n",
       "      <td>0.490569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>well</td>\n",
       "      <td>1.794864</td>\n",
       "      <td>2.367732</td>\n",
       "      <td>-0.142330</td>\n",
       "      <td>0.735045</td>\n",
       "      <td>0.674124</td>\n",
       "      <td>-0.099631</td>\n",
       "      <td>0.088953</td>\n",
       "      <td>0.732747</td>\n",
       "      <td>1.582632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045020</td>\n",
       "      <td>-0.176293</td>\n",
       "      <td>-0.606731</td>\n",
       "      <td>-1.478055</td>\n",
       "      <td>0.294860</td>\n",
       "      <td>-0.703321</td>\n",
       "      <td>0.895588</td>\n",
       "      <td>-0.208934</td>\n",
       "      <td>0.127336</td>\n",
       "      <td>1.136565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>time</td>\n",
       "      <td>-1.332098</td>\n",
       "      <td>-1.141825</td>\n",
       "      <td>-1.057989</td>\n",
       "      <td>-0.560103</td>\n",
       "      <td>0.154454</td>\n",
       "      <td>0.128888</td>\n",
       "      <td>-1.479478</td>\n",
       "      <td>-0.951743</td>\n",
       "      <td>1.372131</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.297017</td>\n",
       "      <td>-0.216625</td>\n",
       "      <td>-0.355595</td>\n",
       "      <td>0.526917</td>\n",
       "      <td>0.948271</td>\n",
       "      <td>0.763656</td>\n",
       "      <td>0.207428</td>\n",
       "      <td>0.195014</td>\n",
       "      <td>-0.724489</td>\n",
       "      <td>0.298700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word        x1        x2        x3        x4        x5        x6  \\\n",
       "0        days  0.939799 -0.072692 -0.970479  0.764277  0.005084  0.117511   \n",
       "1      glitch -0.187341 -1.141623  0.528267  0.468640 -1.393529  0.200473   \n",
       "2        unit  1.527640  0.259914 -0.744607 -1.541466  1.504610  0.358284   \n",
       "3        love  1.088039  0.799649 -0.056783 -0.642312  0.689861  0.118699   \n",
       "4    exchange  0.041626  0.385806 -0.161574  1.478175 -0.883460  0.212744   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "60         of  0.869975 -0.539592  1.452256  1.815241  0.302172  1.918517   \n",
       "61  impressed  0.326595 -0.304986  2.031691 -0.350441 -1.221668  0.026647   \n",
       "62     coming -0.434894 -0.735902 -0.198579  0.900158  1.309612  0.546925   \n",
       "63       well  1.794864  2.367732 -0.142330  0.735045  0.674124 -0.099631   \n",
       "64       time -1.332098 -1.141825 -1.057989 -0.560103  0.154454  0.128888   \n",
       "\n",
       "          x7        x8        x9  ...       x41       x42       x43       x44  \\\n",
       "0  -0.822014  0.656016  0.222889  ...  0.246136 -0.994582  1.446947 -0.132918   \n",
       "1   0.410444  0.088482 -1.088427  ... -0.402051  1.283518 -0.739742  0.616822   \n",
       "2  -0.055283  0.531721  0.011619  ... -0.790788 -0.022923  0.614775  0.558936   \n",
       "3  -0.260751  1.538907 -0.531299  ... -0.385175  1.642984 -0.324092  1.695246   \n",
       "4  -0.285856  0.071793  1.351103  ... -2.041175  1.338348  0.501510 -1.734342   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "60 -1.295815 -0.315433  0.311235  ... -0.060091 -1.204293 -0.887394  0.324741   \n",
       "61  0.948178  0.335767  0.458206  ... -0.501210 -0.162042 -0.170697 -1.744612   \n",
       "62  1.014227  0.202772  0.718133  ...  0.642574 -0.287559 -0.582734 -0.065121   \n",
       "63  0.088953  0.732747  1.582632  ... -0.045020 -0.176293 -0.606731 -1.478055   \n",
       "64 -1.479478 -0.951743  1.372131  ... -1.297017 -0.216625 -0.355595  0.526917   \n",
       "\n",
       "         x45       x46       x47       x48       x49       x50  \n",
       "0   1.080357  1.574163  1.063431  0.705174 -0.153600  0.511467  \n",
       "1   0.633267  1.597046  1.230733  0.165973  0.707445 -0.722897  \n",
       "2   0.518648 -0.755605  0.235046  1.154372  1.399253 -0.368122  \n",
       "3   0.725493 -0.499327  0.758729  0.740417 -0.460985  1.670823  \n",
       "4   0.717494 -0.605008  0.322809  0.563093 -0.080149 -0.035231  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "60  0.756478 -0.259807 -0.073089 -0.940413  0.499771  0.622067  \n",
       "61  0.302444  1.170005  0.598283 -2.103957  0.710737 -0.583350  \n",
       "62  0.664541 -1.016463  0.321847  0.231035 -0.192306  0.490569  \n",
       "63  0.294860 -0.703321  0.895588 -0.208934  0.127336  1.136565  \n",
       "64  0.948271  0.763656  0.207428  0.195014 -0.724489  0.298700  \n",
       "\n",
       "[65 rows x 51 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x'+str(i) for i in range(1, EMBEDDING_DIM+1)])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word'] + ['x'+str(i) for i in range(1, EMBEDDING_DIM+1)]]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "#     ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "# PADDING = 1.0\n",
    "# x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "# y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "# x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "# y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "# plt.xlim(x_axis_min,x_axis_max)\n",
    "# plt.ylim(y_axis_min,y_axis_max)\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to csv\n",
    "w2v_df.to_csv('w2v_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilarity(word, model, n = 10):\n",
    "    # get the index of the word\n",
    "  \n",
    "    word_vec = list(w2v_df[w2v_df['word'] == word].values[0])[1:]\n",
    "    similarities = []\n",
    "    for index, row in w2v_df.iterrows():\n",
    "        if row['word'] == word:\n",
    "            continue\n",
    "        similarities.append((row['word'], cosine_similarity(word_vec, list(row)[1:])))\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('well', 0.33368500147873625), ('got', 0.31847343848889964), ('ease', 0.2768834139469381), ('love', 0.22028789144405328), ('coming', 0.21684597084694407), ('option', 0.20082822510856896), ('contacted', 0.19742697251107186), ('person', 0.18055928692072787), ('instructions', 0.1761952300034511), ('nothing', 0.17218533851667098)]\n"
     ]
    }
   ],
   "source": [
    "print(findSimilarity('bigger', w2v_df, n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0880392789840698,\n",
       " 0.799649178981781,\n",
       " -0.056783244013786316,\n",
       " -0.6423118710517883,\n",
       " 0.6898607015609741,\n",
       " 0.11869940906763077,\n",
       " -0.2607506513595581,\n",
       " 1.5389068126678467,\n",
       " -0.5312985777854919,\n",
       " -1.1486507654190063,\n",
       " -2.397254228591919,\n",
       " -0.12846669554710388,\n",
       " 1.529862642288208,\n",
       " 2.1785366535186768,\n",
       " 0.4197899401187897,\n",
       " 0.725969135761261,\n",
       " 1.2426855564117432,\n",
       " -2.1740548610687256,\n",
       " 1.2013800144195557,\n",
       " 1.6401646137237549,\n",
       " -0.08999241143465042,\n",
       " -0.8410106897354126,\n",
       " 0.7160742282867432,\n",
       " 0.3351263999938965,\n",
       " 0.13558551669120789,\n",
       " 1.3662101030349731,\n",
       " 1.1011170148849487,\n",
       " 0.4691050052642822,\n",
       " 0.7881497144699097,\n",
       " 0.5187317132949829,\n",
       " 0.7334776520729065,\n",
       " 0.18310797214508057,\n",
       " -1.2190450429916382,\n",
       " -0.6486284136772156,\n",
       " 0.8288964629173279,\n",
       " 0.4706714451313019,\n",
       " 1.9058754444122314,\n",
       " 0.18385061621665955,\n",
       " -0.659069299697876,\n",
       " -0.0752599835395813,\n",
       " -0.38517534732818604,\n",
       " 1.6429835557937622,\n",
       " -0.32409191131591797,\n",
       " 1.6952455043792725,\n",
       " 0.7254928946495056,\n",
       " -0.4993272125720978,\n",
       " 0.7587293982505798,\n",
       " 0.74041748046875,\n",
       " -0.46098509430885315,\n",
       " 1.6708232164382935]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the row where word column is 'love'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
